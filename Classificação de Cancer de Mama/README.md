
# ü©∫ Classifica√ß√£o de C√¢ncer de Mama - Machine Learning para Diagn√≥stico M√©dico

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3%2B-orange)](https://scikit-learn.org)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.7%2B-green)](https://xgboost.readthedocs.io)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## üìä Coleta de Dados

- **Fonte**: [Breast Cancer Wisconsin Dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))  
- **Total de amostras**: 569  
- **Features**: 30 vari√°veis num√©ricas extra√≠das de imagens de n√∫cleos celulares  
- **Classes alvo**:  
  - Benigno (B) ‚Üí 357 casos (62,7%)  
  - Maligno (M) ‚Üí 212 casos (37,3%)  

### Pr√©-processamento realizado:
1. Remo√ß√£o de colunas irrelevantes (`id`, `Unnamed: 32`)  
2. Codifica√ß√£o da vari√°vel alvo (`B` = 0, `M` = 1)  
3. Sele√ß√£o das **top 10 features mais correlacionadas**  
4. Tratamento de **outliers com IQR**  
5. **Padroniza√ß√£o** com `StandardScaler`  
6. **Redu√ß√£o de dimensionalidade (PCA)** garantindo ‚â•95% de vari√¢ncia explicada  

---

## ü§ñ Modelagem

### Passos do pipeline:
1. **Divis√£o Treino/Teste**: 70% / 30% (estratificado)  
2. **Balanceamento**: Aplica√ß√£o de **SMOTE** apenas nos dados de treino  
3. **Modelos testados**:
   - Regress√£o Log√≠stica  
   - Random Forest  
   - XGBoost  
   - Ensemble (Voting, Stacking e Calibrated Models)  

### Avalia√ß√£o:
- **M√©trica priorit√°ria**: **Recall** (importante para identificar todos os casos malignos)  
- Outras m√©tricas utilizadas: **Accuracy, Precision, F1-score e AUC**  

---

## üìà Resultados

### Compara√ß√£o Final dos Modelos (ordenados por Recall):
| Modelo                | Accuracy |   AUC  | Recall |
|------------------------|----------|--------|--------|
| Logistic Regression    | 0.9103   | 0.9924 | 1.0000 |
| Random Forest          | 0.9744   | 0.9962 | 0.9796 |
| Voting Classifier      | 0.9551   | 0.9950 | 0.9796 |
| Stacking Classifier    | 0.9615   | 0.9952 | 0.9796 |
| Calibrated Model       | 0.9679   | 0.9969 | 0.9796 |
| XGBoost                | 0.9423   | 0.9924 | 0.9592 |

---

## üèÜ Conclus√µes

- üéØ **Modelos com Recall perfeito (100%)**:  
  - Regress√£o Log√≠stica detectou **todos os casos malignos**.  

- üèÜ **Melhor Modelo (Recall + AUC)**:  
  - **Logistic Regression** ‚Üí Recall = 1.000 e AUC = 0.9924  
  - Apesar da menor acur√°cia em rela√ß√£o a Random Forest e outros ensembles, √© o modelo **mais indicado em aplica√ß√µes m√©dicas**, pois garante **nenhum falso negativo** (n√£o deixa passar c√¢ncer sem diagn√≥stico).  

- ‚úÖ Este estudo demonstra a import√¢ncia de escolher a m√©trica adequada (nesse caso, **Recall**) em problemas de sa√∫de, onde um falso negativo pode ter consequ√™ncias graves.  

---

üìå **Pr√≥ximos passos sugeridos**:
- Testar mais t√©cnicas de sele√ß√£o de features (ex: RFE, SHAP Values).  
- Avaliar outros algoritmos de ensemble.  
- Realizar valida√ß√£o cruzada estratificada para maior robustez.  

---

üë®‚Äçüíª Desenvolvido por **Emerson Martins**  
üìÖ Projeto de Portf√≥lio em Ci√™ncia de Dados  
